{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import locale\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import dates\n",
    "# models\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import pmdarima as pm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sys\n",
    "sys.path.append('/code/src/')\n",
    "from my_functions import train_test_time_series, evaluate_forecast, load_dataframe_from_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Leer datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_load = \"../../data/\"\n",
    "file_name = \"processed/df_time_monthly.csv\"\n",
    "full_path = path_load + file_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 sarimax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo construir automáticamente el modelo SARIMAX en python\n",
    "Now let’s practice adding in an exogenous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = load_dataframe_from_csv(full_path)\n",
    "exog_vars = ['holidays_cont', 'month', 'year', 'days_in_month', 'is_first_month', 'is_last_month']\n",
    "endog_var = 'cost'\n",
    "\n",
    "exog = df[exog_vars]\n",
    "endog = df[endog_var]\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "train_size = int(len(df) * 0.8)  # Porcentaje de datos para entrenamiento\n",
    "train_endog = endog[:train_size]\n",
    "train_exog = exog[:train_size]\n",
    "test_endog = endog[train_size:]\n",
    "test_exog = exog[train_size:]\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model = pm.auto_arima(train_endog, exogenous=train_exog, seasonal=True, trace=True)\n",
    "# Obtener los valores del modelo seleccionado\n",
    "order = model.order\n",
    "\n",
    "print(order)\n",
    "\n",
    "# Realizar la predicción en los datos de prueba\n",
    "forecast = model.predict(n_periods=len(test_endog), exogenous=test_exog)\n",
    "\n",
    "# Evaluar el rendimiento del modelo en los datos de prueba\n",
    "# Aquí puedes utilizar las métricas adecuadas según el problema, como el error cuadrático medio (MSE) o el error absoluto medio (MAE).\n",
    "forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Cuadrático Medio (MSE): El MSE mide el promedio de los errores al cuadrado entre las predicciones y los valores reales. Cuanto más bajo sea el MSE, mejor será el modelo en términos de ajuste a los datos observados.\n",
    "\n",
    "Error Absoluto Medio (MAE): El MAE mide el promedio de los errores absolutos entre las predicciones y los valores reales. Esta métrica proporciona una medida del error promedio en la misma escala que los datos originales.\n",
    "\n",
    "R-squared (R2): El coeficiente de determinación R-cuadrado representa la proporción de la varianza en la variable objetivo que es explicada por el modelo. Un valor más cercano a 1 indica un mejor ajuste del modelo a los datos observados.\n",
    "\n",
    "Error Porcentual Absoluto Medio (MAPE): El MAPE mide el promedio de los errores porcentuales absolutos entre las predicciones y los valores reales. Esta métrica puede proporcionar una medida relativa del error en relación con el tamaño de los valores reales.\n",
    "\n",
    "Es importante considerar que ninguna métrica de error es perfecta por sí misma. Por lo tanto, puede ser útil evaluar y comparar varias métricas en conjunto para tener una imagen más completa del rendimiento del modelo.\n",
    "\n",
    "En tu pipeline, puedes aplicar diferentes modelos de aprendizaje automático, como regresión lineal, regresión de árboles de decisión, regresión de bosques aleatorios, regresión de Gradient Boosting, entre otros. Luego, puedes calcular y comparar las métricas de error mencionadas anteriormente para cada modelo y seleccionar aquel que presente el mejor rendimiento en función de tus objetivos y necesidades específicas.\n",
    "\n",
    "Recuerda que también es importante considerar otros factores, como la interpretabilidad del modelo, la simplicidad, el tiempo de entrenamiento y la capacidad de escalabilidad, además de las métricas de error, al seleccionar el mejor modelo para tus necesidades particulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate_forecast(test_endog, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order (1, 1, 0)\n",
      "seasonal_order (0, 0, 0, 0)\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            8     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11224D+01    |proj g|=  1.21697D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    8      4      6      1     0     0   1.027D-07   9.630D+00\n",
      "  F =   9.6297422151482568     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "                                     SARIMAX Results                                      \n",
      "==========================================================================================\n",
      "Dep. Variable:                               cost   No. Observations:                   35\n",
      "Model:             SARIMAX(1, 1, 0)x(0, 1, 0, 12)   Log Likelihood                -337.041\n",
      "Date:                            Sat, 20 May 2023   AIC                            690.082\n",
      "Time:                                    14:53:33   BIC                            698.810\n",
      "Sample:                                09-30-2019   HQIC                           692.138\n",
      "                                     - 07-31-2022                                         \n",
      "Covariance Type:                              opg                                         \n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "holidays_cont  -2.434e+05    1.2e+06     -0.203      0.839   -2.59e+06     2.1e+06\n",
      "month           7.578e-09   2588.054   2.93e-12      1.000   -5072.492    5072.492\n",
      "year            1.911e-06   6.53e+05   2.93e-12      1.000   -1.28e+06    1.28e+06\n",
      "days_in_month  -1.508e+06   1.06e+06     -1.424      0.155   -3.58e+06    5.68e+05\n",
      "is_first_month          0   3.09e-10          0      1.000   -6.06e-10    6.06e-10\n",
      "is_last_month           0   2.55e-11          0      1.000   -4.99e-11    4.99e-11\n",
      "ar.L1              0.0166      0.402      0.041      0.967      -0.772       0.805\n",
      "sigma2          1.176e+12      0.293   4.01e+12      0.000    1.18e+12    1.18e+12\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   1.19   Jarque-Bera (JB):                 2.47\n",
      "Prob(Q):                              0.28   Prob(JB):                         0.29\n",
      "Heteroskedasticity (H):               0.25   Skew:                            -0.68\n",
      "Prob(H) (two-sided):                  0.09   Kurtosis:                         3.92\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "[2] Covariance matrix is singular or near-singular, with condition number 8.86e+47. Standard errors may be unstable.\n",
      "Model: SARIMA\n",
      "╒══════════════════════════════════════════════════╤════════════════════════╕\n",
      "│ Metric                                           │ Value                  │\n",
      "╞══════════════════════════════════════════════════╪════════════════════════╡\n",
      "│ **Scale-Dependent Metrics**                      │                        │\n",
      "├──────────────────────────────────────────────────┼────────────────────────┤\n",
      "│ Mean Squared Error (MSE):                        │ $ 2.065.585.407.924,88 │\n",
      "├──────────────────────────────────────────────────┼────────────────────────┤\n",
      "│ Mean Absolute Error (MAE):                       │ $ 1.169.439,37         │\n",
      "├──────────────────────────────────────────────────┼────────────────────────┤\n",
      "│ Root Mean Squared Error (RMSE):                  │ $ 1.437.214,46         │\n",
      "├──────────────────────────────────────────────────┼────────────────────────┤\n",
      "│ **Percentage-Error Metrics**                     │                        │\n",
      "├──────────────────────────────────────────────────┼────────────────────────┤\n",
      "│ Mean Absolute percentage Error (MAPE)            │ 38.66%                 │\n",
      "├──────────────────────────────────────────────────┼────────────────────────┤\n",
      "│ Symmetric Mean Absolute percentage Error (SMAPE) │ 29.85%                 │\n",
      "╘══════════════════════════════════════════════════╧════════════════════════╛\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mse': 2065585407924.8767,\n",
       " 'mae': 1169439.369321766,\n",
       " 'r2': -1.8107850774768917,\n",
       " 'RMSE': 1437214.4613539334,\n",
       " 'MAPE': 0.38663274648689977,\n",
       " 'SMAPE': 29.85427592797335,\n",
       " 'MAPE_percent': 38.66}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar y preparar los datos\n",
    "data_sarima = load_dataframe_from_csv(full_path)\n",
    "data_sarima.index.freq = 'M'\n",
    "X = data_sarima.drop('cost', axis=1)  # Variables exógenas\n",
    "y = data_sarima['cost']  # Variable objetivo\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba basado en el índice de tiempo\n",
    "train_size = int(len(data_sarima) * 0.8)\n",
    "train_X, train_y = X[:train_size], y[:train_size]\n",
    "test_X, test_y = X[train_size:], y[train_size:]\n",
    "\n",
    "# Ajustar modelo Auto ARIMA\n",
    "model_arima = pm.auto_arima(train_y, exogenous=train_X, seasonal=True)\n",
    "y_pred_arima = model_arima.predict(n_periods=len(test_y), exogenous=test_X)\n",
    "# Ajustar modelo SARIMA\n",
    "order = model_arima.order\n",
    "seasonal_order = model_arima.seasonal_order\n",
    "print('order', order)\n",
    "print('seasonal_order', seasonal_order)\n",
    "# order=(1,1,0), seasonal_order=(0,1,0,12)\n",
    "model_sarima = SARIMAX(train_y, exog=train_X, order=(1,1,0), seasonal_order=(0,1,0,12))\n",
    "model_sarima_fit = model_sarima.fit()\n",
    "# Obtener el resumen del modelo\n",
    "print(model_sarima_fit.summary())\n",
    "print(\"Model: SARIMA\")\n",
    "# Predecir con SARIMA\n",
    "y_pred_sarima = model_sarima_fit.predict(start=len(train_y), end=len(train_y) + len(test_y) - 1, exog=test_X)\n",
    "evaluate_forecast(test_y, y_pred_sarima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MAL train testpero guia para PIPELINE de 3 modelos\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# # Cargar y preparar los datos\n",
    "# path_load = \"../../data/\"\n",
    "# file_name = \"processed/df_time_monthly.csv\"\n",
    "# full_path = path_load + file_name\n",
    "# data = pd.read_csv(full_path, parse_dates=True)\n",
    "# data['date'] = pd.to_datetime(data['date'])\n",
    "# data['date'] = data['date'].dt.tz_localize(None)\n",
    "# data.set_index('date', inplace=True)\n",
    "# data.index.freq = 'M'\n",
    "# # data = pd.read_csv('datos.csv')  # Suponiendo que los datos están en un archivo CSV\n",
    "# X = data.drop('cost', axis=1)  # Variables exógenas\n",
    "# y = data['cost']  # Variable objetivo\n",
    "\n",
    "# # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Definir los modelos a evaluar en el pipeline\n",
    "# models = [\n",
    "#     ('Linear Regression', LinearRegression()),\n",
    "#     ('Random Forest', RandomForestRegressor()),\n",
    "#     ('Auto ARIMA', pm.auto_arima)\n",
    "# ]\n",
    "\n",
    "# # Entrenar y evaluar los modelos en el pipeline\n",
    "# for model_name, model in models:\n",
    "#     if model_name == 'Auto ARIMA':\n",
    "#         model.fit(y_train, exogenous=X_train)\n",
    "#         y_pred = model.predict(n_periods=len(y_test), exogenous=X_test)\n",
    "#     else:\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "    \n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     mae = mean_absolute_error(y_test, y_pred)\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "#     print(f\"Model: {model_name}\")\n",
    "#     # Configurar locale para mostrar los valores en pesos colombianos\n",
    "#     locale.setlocale(locale.LC_MONETARY, 'es_CO.UTF-8')\n",
    "    \n",
    "#     print(\"Mean Squared Error (MSE): {}\".format(locale.currency(mse, grouping=True)))\n",
    "#     print(\"Mean Absolute Error (MAE): {}\".format(locale.currency(mae, grouping=True)))\n",
    "#     print(\"R-squared (R2): {:.2f}\".format(r2))\n",
    "#     print('---')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargar y preparar los datos\n",
    "data = load_dataframe_from_csv(full_path)\n",
    "data.index.freq = 'M'\n",
    "X = data.drop('cost', axis=1)  # Variables exógenas\n",
    "y = data['cost']  # Variable objetivo\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba basado en el índice de tiempo\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_X, train_y = X[:train_size], y[:train_size]\n",
    "test_X, test_y = X[train_size:], y[train_size:]\n",
    "\n",
    "# Ajustar modelo Auto ARIMA\n",
    "model_arima = pm.auto_arima(train_y, exogenous=train_X, seasonal=True)\n",
    "y_pred_arima = model_arima.predict(n_periods=len(test_y), exogenous=test_X)\n",
    "\n",
    "# Ajustar modelo SARIMA\n",
    "order = model_arima.order\n",
    "seasonal_order = model_arima.seasonal_order\n",
    "model_sarima = SARIMAX(train_y, exog=train_X, order=order, seasonal_order=seasonal_order)\n",
    "model_sarima_fit = model_sarima.fit()\n",
    "\n",
    "# Predecir con SARIMA\n",
    "y_pred_sarima = model_sarima_fit.predict(start=len(train_y), end=len(train_y) + len(test_y) - 1, exog=test_X)\n",
    "\n",
    "# Definir los modelos a evaluar en el pipeline\n",
    "models = [\n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('Random Forest', RandomForestRegressor())\n",
    "]\n",
    "\n",
    "# Entrenar y evaluar los modelos en el pipeline\n",
    "for model_name, model in models:\n",
    "    model.fit(train_X, train_y)\n",
    "    y_pred = model.predict(test_X)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    evaluate_forecast(test_y, y_pred)\n",
    "    print('---')\n",
    "\n",
    "# Calcular métricas para Auto ARIMA\n",
    "print(\"Model: Auto ARIMA\")\n",
    "evaluate_forecast(test_y, y_pred_arima)\n",
    "print('---')\n",
    "\n",
    "# Calcular métricas para SARIMA\n",
    "print(\"Model: SARIMA\")\n",
    "evaluate_forecast(test_y, y_pred_sarima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
