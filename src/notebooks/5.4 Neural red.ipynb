{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcdb2211-73e7-4a7f-af07-25ef7acc7891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 03:03:14.343455: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-03 03:03:14.497412: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-03 03:03:14.955285: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-03 03:03:14.956797: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-03 03:03:15.951564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import sys\n",
    "sys.path.append('/code/src/')\n",
    "from my_functions import train_test_time_series, evaluate_forecast, load_dataframe_from_csv, split_train_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354591b7-1202-48c3-ad2b-faee1327bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño set de entrenamiento: (36,)\n",
      "Tamaño set de prueba: (10,)\n",
      "Tamaños entrada (BATCHES x INPUT_LENGTH x FEATURES) y de salida (BATCHES x OUTPUT_LENGTH x FEATURES)\n",
      "Set de entrenamiento - x_tr: (33, 3, 1), y_tr: (33, 1, 1)\n",
      "Set de prueba - x_ts: (7, 3, 1), y_ts: (7, 1, 1)\n",
      "Min x_tr/x_ts sin escalamiento: 645200/2505194\n",
      "Min x_tr/x_ts con escalamiento: -1.3069970656643133/0.4012460828971006\n",
      "\n",
      "Min y_tr/y_ts sin escalamiento: 645200/2505194\n",
      "Min y_tr/y_ts con escalamiento: -1.3303845156102565/0.33403438617066356\n",
      "\n",
      "Max x_tr/x_ts sin escalamiento: 4345208/5296946\n",
      "Max x_tr/x_ts con escalamiento: 2.224455437243326/3.421009231253509\n",
      "\n",
      "Max y_tr/y_ts sin escalamiento: 4345208/3359652\n",
      "Max y_tr/y_ts con escalamiento: 1.9805741498158784/1.0986476300724834\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 03:03:18.068341: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-03 03:03:18.070031: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-03 03:03:18.070892: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-03 03:03:18.151374: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [33,1,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-07-03 03:03:18.151596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [33,1,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-07-03 03:03:18.369893: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-03 03:03:18.371154: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-03 03:03:18.372151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-03 03:03:18.737321: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-03 03:03:18.738725: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-03 03:03:18.739608: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 1s - loss: 0.8600 - 1s/epoch - 1s/step\n",
      "Epoch 2/80\n",
      "1/1 - 0s - loss: 0.8571 - 4ms/epoch - 4ms/step\n",
      "Epoch 3/80\n",
      "1/1 - 0s - loss: 0.8549 - 5ms/epoch - 5ms/step\n",
      "Epoch 4/80\n",
      "1/1 - 0s - loss: 0.8531 - 4ms/epoch - 4ms/step\n",
      "Epoch 5/80\n",
      "1/1 - 0s - loss: 0.8514 - 3ms/epoch - 3ms/step\n",
      "Epoch 6/80\n",
      "1/1 - 0s - loss: 0.8500 - 4ms/epoch - 4ms/step\n",
      "Epoch 7/80\n",
      "1/1 - 0s - loss: 0.8486 - 4ms/epoch - 4ms/step\n",
      "Epoch 8/80\n",
      "1/1 - 0s - loss: 0.8473 - 3ms/epoch - 3ms/step\n",
      "Epoch 9/80\n",
      "1/1 - 0s - loss: 0.8460 - 3ms/epoch - 3ms/step\n",
      "Epoch 10/80\n",
      "1/1 - 0s - loss: 0.8448 - 6ms/epoch - 6ms/step\n",
      "Epoch 11/80\n",
      "1/1 - 0s - loss: 0.8436 - 9ms/epoch - 9ms/step\n",
      "Epoch 12/80\n",
      "1/1 - 0s - loss: 0.8425 - 10ms/epoch - 10ms/step\n",
      "Epoch 13/80\n",
      "1/1 - 0s - loss: 0.8414 - 4ms/epoch - 4ms/step\n",
      "Epoch 14/80\n",
      "1/1 - 0s - loss: 0.8403 - 4ms/epoch - 4ms/step\n",
      "Epoch 15/80\n",
      "1/1 - 0s - loss: 0.8392 - 4ms/epoch - 4ms/step\n",
      "Epoch 16/80\n",
      "1/1 - 0s - loss: 0.8381 - 4ms/epoch - 4ms/step\n",
      "Epoch 17/80\n",
      "1/1 - 0s - loss: 0.8371 - 4ms/epoch - 4ms/step\n",
      "Epoch 18/80\n",
      "1/1 - 0s - loss: 0.8361 - 5ms/epoch - 5ms/step\n",
      "Epoch 19/80\n",
      "1/1 - 0s - loss: 0.8350 - 4ms/epoch - 4ms/step\n",
      "Epoch 20/80\n",
      "1/1 - 0s - loss: 0.8340 - 3ms/epoch - 3ms/step\n",
      "Epoch 21/80\n",
      "1/1 - 0s - loss: 0.8330 - 4ms/epoch - 4ms/step\n",
      "Epoch 22/80\n",
      "1/1 - 0s - loss: 0.8320 - 4ms/epoch - 4ms/step\n",
      "Epoch 23/80\n",
      "1/1 - 0s - loss: 0.8311 - 4ms/epoch - 4ms/step\n",
      "Epoch 24/80\n",
      "1/1 - 0s - loss: 0.8301 - 4ms/epoch - 4ms/step\n",
      "Epoch 25/80\n",
      "1/1 - 0s - loss: 0.8291 - 3ms/epoch - 3ms/step\n",
      "Epoch 26/80\n",
      "1/1 - 0s - loss: 0.8281 - 3ms/epoch - 3ms/step\n",
      "Epoch 27/80\n",
      "1/1 - 0s - loss: 0.8272 - 4ms/epoch - 4ms/step\n",
      "Epoch 28/80\n",
      "1/1 - 0s - loss: 0.8262 - 4ms/epoch - 4ms/step\n",
      "Epoch 29/80\n",
      "1/1 - 0s - loss: 0.8253 - 4ms/epoch - 4ms/step\n",
      "Epoch 30/80\n",
      "1/1 - 0s - loss: 0.8243 - 3ms/epoch - 3ms/step\n",
      "Epoch 31/80\n",
      "1/1 - 0s - loss: 0.8234 - 4ms/epoch - 4ms/step\n",
      "Epoch 32/80\n",
      "1/1 - 0s - loss: 0.8224 - 3ms/epoch - 3ms/step\n",
      "Epoch 33/80\n",
      "1/1 - 0s - loss: 0.8215 - 6ms/epoch - 6ms/step\n",
      "Epoch 34/80\n",
      "1/1 - 0s - loss: 0.8206 - 4ms/epoch - 4ms/step\n",
      "Epoch 35/80\n",
      "1/1 - 0s - loss: 0.8196 - 3ms/epoch - 3ms/step\n",
      "Epoch 36/80\n",
      "1/1 - 0s - loss: 0.8187 - 4ms/epoch - 4ms/step\n",
      "Epoch 37/80\n",
      "1/1 - 0s - loss: 0.8178 - 4ms/epoch - 4ms/step\n",
      "Epoch 38/80\n",
      "1/1 - 0s - loss: 0.8169 - 3ms/epoch - 3ms/step\n",
      "Epoch 39/80\n",
      "1/1 - 0s - loss: 0.8159 - 4ms/epoch - 4ms/step\n",
      "Epoch 40/80\n",
      "1/1 - 0s - loss: 0.8150 - 3ms/epoch - 3ms/step\n",
      "Epoch 41/80\n",
      "1/1 - 0s - loss: 0.8141 - 3ms/epoch - 3ms/step\n",
      "Epoch 42/80\n",
      "1/1 - 0s - loss: 0.8132 - 4ms/epoch - 4ms/step\n",
      "Epoch 43/80\n",
      "1/1 - 0s - loss: 0.8123 - 3ms/epoch - 3ms/step\n",
      "Epoch 44/80\n",
      "1/1 - 0s - loss: 0.8113 - 4ms/epoch - 4ms/step\n",
      "Epoch 45/80\n",
      "1/1 - 0s - loss: 0.8104 - 3ms/epoch - 3ms/step\n",
      "Epoch 46/80\n",
      "1/1 - 0s - loss: 0.8095 - 4ms/epoch - 4ms/step\n",
      "Epoch 47/80\n",
      "1/1 - 0s - loss: 0.8086 - 3ms/epoch - 3ms/step\n",
      "Epoch 48/80\n",
      "1/1 - 0s - loss: 0.8077 - 3ms/epoch - 3ms/step\n",
      "Epoch 49/80\n",
      "1/1 - 0s - loss: 0.8068 - 4ms/epoch - 4ms/step\n",
      "Epoch 50/80\n",
      "1/1 - 0s - loss: 0.8059 - 4ms/epoch - 4ms/step\n",
      "Epoch 51/80\n",
      "1/1 - 0s - loss: 0.8050 - 3ms/epoch - 3ms/step\n",
      "Epoch 52/80\n",
      "1/1 - 0s - loss: 0.8041 - 4ms/epoch - 4ms/step\n",
      "Epoch 53/80\n",
      "1/1 - 0s - loss: 0.8032 - 3ms/epoch - 3ms/step\n",
      "Epoch 54/80\n",
      "1/1 - 0s - loss: 0.8023 - 4ms/epoch - 4ms/step\n",
      "Epoch 55/80\n",
      "1/1 - 0s - loss: 0.8014 - 4ms/epoch - 4ms/step\n",
      "Epoch 56/80\n",
      "1/1 - 0s - loss: 0.8005 - 12ms/epoch - 12ms/step\n",
      "Epoch 57/80\n",
      "1/1 - 0s - loss: 0.7996 - 10ms/epoch - 10ms/step\n",
      "Epoch 58/80\n",
      "1/1 - 0s - loss: 0.7987 - 4ms/epoch - 4ms/step\n",
      "Epoch 59/80\n",
      "1/1 - 0s - loss: 0.7978 - 3ms/epoch - 3ms/step\n",
      "Epoch 60/80\n",
      "1/1 - 0s - loss: 0.7969 - 4ms/epoch - 4ms/step\n",
      "Epoch 61/80\n",
      "1/1 - 0s - loss: 0.7960 - 5ms/epoch - 5ms/step\n",
      "Epoch 62/80\n",
      "1/1 - 0s - loss: 0.7951 - 4ms/epoch - 4ms/step\n",
      "Epoch 63/80\n",
      "1/1 - 0s - loss: 0.7942 - 4ms/epoch - 4ms/step\n",
      "Epoch 64/80\n",
      "1/1 - 0s - loss: 0.7933 - 4ms/epoch - 4ms/step\n",
      "Epoch 65/80\n",
      "1/1 - 0s - loss: 0.7924 - 4ms/epoch - 4ms/step\n",
      "Epoch 66/80\n",
      "1/1 - 0s - loss: 0.7915 - 4ms/epoch - 4ms/step\n",
      "Epoch 67/80\n",
      "1/1 - 0s - loss: 0.7907 - 4ms/epoch - 4ms/step\n",
      "Epoch 68/80\n",
      "1/1 - 0s - loss: 0.7898 - 3ms/epoch - 3ms/step\n",
      "Epoch 69/80\n",
      "1/1 - 0s - loss: 0.7889 - 4ms/epoch - 4ms/step\n",
      "Epoch 70/80\n",
      "1/1 - 0s - loss: 0.7880 - 4ms/epoch - 4ms/step\n",
      "Epoch 71/80\n",
      "1/1 - 0s - loss: 0.7871 - 4ms/epoch - 4ms/step\n",
      "Epoch 72/80\n",
      "1/1 - 0s - loss: 0.7862 - 3ms/epoch - 3ms/step\n",
      "Epoch 73/80\n",
      "1/1 - 0s - loss: 0.7854 - 4ms/epoch - 4ms/step\n",
      "Epoch 74/80\n",
      "1/1 - 0s - loss: 0.7845 - 4ms/epoch - 4ms/step\n",
      "Epoch 75/80\n",
      "1/1 - 0s - loss: 0.7836 - 4ms/epoch - 4ms/step\n",
      "Epoch 76/80\n",
      "1/1 - 0s - loss: 0.7827 - 5ms/epoch - 5ms/step\n",
      "Epoch 77/80\n",
      "1/1 - 0s - loss: 0.7819 - 4ms/epoch - 4ms/step\n",
      "Epoch 78/80\n",
      "1/1 - 0s - loss: 0.7810 - 4ms/epoch - 4ms/step\n",
      "Epoch 79/80\n",
      "1/1 - 0s - loss: 0.7801 - 4ms/epoch - 4ms/step\n",
      "Epoch 80/80\n",
      "1/1 - 0s - loss: 0.7792 - 4ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 03:03:19.881438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype float and shape [33,3,1]\n",
      "\t [[{{node Placeholder/_10}}]]\n",
      "2023-07-03 03:03:19.881655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [33,1,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-07-03 03:03:20.038289: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-03 03:03:20.039360: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-03 03:03:20.040322: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparativo desempeños:\n",
      "  RMSE train:\t 0.778\n",
      "  RMSE test:\t 0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 03:03:20.176872: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [7,1,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-07-03 03:03:20.177063: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [7,1,1]\n",
      "\t [[{{node Placeholder/_11}}]]\n"
     ]
    }
   ],
   "source": [
    "#mio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "from IPython.display import display\n",
    "import sys\n",
    "sys.path.append('/code/src/')\n",
    "from my_functions import train_test_time_series, evaluate_forecast, load_dataframe_from_csv, split_train_test_data\n",
    "def create_sequences(data, sequence_length, output_length):\n",
    "    X, Y = [], []\n",
    "    shape = data.shape\n",
    "    if len(shape)==1: # Si tenemos sólo una serie (univariado)\n",
    "        rows, cols = data.shape[0], 1\n",
    "        data = data.reshape(rows,cols)\n",
    "    else:\n",
    "        rows, cols = data.shape\n",
    "    # Generar los arreglo\n",
    "    for i in range(rows- sequence_length):\n",
    "        X.append(data[i: i + sequence_length, 0: cols])\n",
    "        Y.append(data[i + sequence_length : i + sequence_length + output_length, -1].reshape(output_length,1))\n",
    "    # Convertir listas a arreglos de NumPy\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "def train_test_split(data):\n",
    "    train_size = int(len(data) * 0.8)\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:]\n",
    "    return train_data, test_data\n",
    "def escalar_dataset(data_input):\n",
    "    NFEATS = data_input['x_tr'].shape[2]\n",
    "\n",
    "    # Generar listado con \"scalers\"\n",
    "    # scalers = [MinMaxScaler(feature_range=(0,1)) for i in range(NFEATS)] #feature_rangetuple (min, max), default=(0, 1)\n",
    "    scalers = [StandardScaler() for i in range(NFEATS)] #feature_rangetuple (min, max), default=(0, 1)\n",
    "\n",
    "    # Arreglos que contendrán los datasets escalados\n",
    "    x_tr_s = np.zeros(data_input['x_tr'].shape)\n",
    "    # x_vl_s = np.zeros(data_input['x_vl'].shape)\n",
    "    x_ts_s = np.zeros(data_input['x_ts'].shape)\n",
    "    y_tr_s = np.zeros(data_input['y_tr'].shape)\n",
    "    # y_vl_s = np.zeros(data_input['y_vl'].shape)\n",
    "    y_ts_s = np.zeros(data_input['y_ts'].shape)\n",
    "\n",
    "    # Escalamiento: se usarán los min/max del set de entrenamiento para\n",
    "    # escalar la totalidad de los datasets\n",
    "    \n",
    "    # Escalamiento Xs\n",
    "    for i in range(NFEATS):\n",
    "        x_tr_s[:,:,i] = scalers[i].fit_transform(data_input['x_tr'][:,:,i])\n",
    "        # x_vl_s[:,:,i] = scalers[i].transform(x_vl[:,:,i])\n",
    "        x_ts_s[:,:,i] = scalers[i].transform(data_input['x_ts'][:,:,i])\n",
    "    \n",
    "    # Escalamiento Ys\n",
    "    y_tr_s[:,:,0] = scalers[-1].fit_transform(data_input['y_tr'][:,:,0])\n",
    "    # y_vl_s[:,:,0] = scalers[-1].transform(y_vl[:,:,0])\n",
    "    y_ts_s[:,:,0] = scalers[-1].transform(data_input['y_ts'][:,:,0])\n",
    "\n",
    "    # Conformar ` de salida\n",
    "    data_scaled = {\n",
    "        'x_tr_s': x_tr_s, 'y_tr_s': y_tr_s,\n",
    "        # 'x_vl_s': x_vl_s, 'y_vl_s': y_vl_s,\n",
    "        'x_ts_s': x_ts_s, 'y_ts_s': y_ts_s,\n",
    "    }\n",
    "\n",
    "    return data_scaled, scalers[0]\n",
    "\n",
    "def main():\n",
    "    path_load = \"../../data/\"\n",
    "    file_name = \"processed/df_time_monthly.csv\"\n",
    "    full_path = path_load + file_name\n",
    "    data = load_dataframe_from_csv(full_path)\n",
    "    data.index.freq = 'M'\n",
    "    #\n",
    "    INPUT_LENGTH = 3\n",
    "    OUTPUT_LENGTH = 1\n",
    "    train_data, test_data =train_test_split(data['cost'])\n",
    "    # Imprimir en pantalla el tamaño de cada subset\n",
    "    print(f'Tamaño set de entrenamiento: {train_data.shape}')\n",
    "    print(f'Tamaño set de prueba: {test_data.shape}')\n",
    "\n",
    "    x_tr, y_tr = create_sequences(train_data.values, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "    x_ts, y_ts = create_sequences(test_data.values, INPUT_LENGTH, OUTPUT_LENGTH)\n",
    "    print('Tamaños entrada (BATCHES x INPUT_LENGTH x FEATURES) y de salida (BATCHES x OUTPUT_LENGTH x FEATURES)')\n",
    "    print(f'Set de entrenamiento - x_tr: {x_tr.shape}, y_tr: {y_tr.shape}')\n",
    "    print(f'Set de prueba - x_ts: {x_ts.shape}, y_ts: {y_ts.shape}')\n",
    "\n",
    "    # Preprocesamiento de los datos\n",
    "    data_in = {\n",
    "    'x_tr': x_tr, 'y_tr': y_tr,\n",
    "    # 'x_vl': x_vl, 'y_vl': y_vl,\n",
    "    'x_ts': x_ts, 'y_ts': y_ts,\n",
    "    }\n",
    "    data_s, scaler = escalar_dataset(data_in)\n",
    "    # Extraer subsets escalados\n",
    "    x_tr_s, y_tr_s = data_s['x_tr_s'], data_s['y_tr_s']\n",
    "    x_ts_s, y_ts_s = data_s['x_ts_s'], data_s['y_ts_s']\n",
    "    \n",
    "    # Verificación\n",
    "    print(f'Min x_tr/x_ts sin escalamiento: {x_tr.min()}/{x_ts.min()}')\n",
    "    print(f'Min x_tr/x_ts con escalamiento: {x_tr_s.min()}/{x_ts_s.min()}')\n",
    "    \n",
    "    print(f'\\nMin y_tr/y_ts sin escalamiento: {y_tr.min()}/{y_ts.min()}')\n",
    "    print(f'Min y_tr/y_ts con escalamiento: {y_tr_s.min()}/{y_ts_s.min()}')\n",
    "    \n",
    "    print(f'\\nMax x_tr/x_ts sin escalamiento: {x_tr.max()}/{x_ts.max()}')\n",
    "    print(f'Max x_tr/x_ts con escalamiento: {x_tr_s.max()}/{x_ts_s.max()}')\n",
    "    \n",
    "    print(f'\\nMax y_tr/y_ts sin escalamiento: {y_tr.max()}/{y_ts.max()}')\n",
    "    print(f'Max y_tr/y_ts con escalamiento: {y_tr_s.max()}/{y_ts_s.max()}')\n",
    "\n",
    "    # Ajustar parámetros para reproducibilidad del entrenamiento\n",
    "    tf.random.set_seed(123)\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "    \n",
    "    # El modelo\n",
    "    N_UNITS = 64 # Tamaño del estado oculto (h) y de la celda de memoria (c)\n",
    "    INPUT_SHAPE = (x_tr_s.shape[1], x_tr_s.shape[2]) # 3 (meses) x 1 (feature)\n",
    "    \n",
    "    modelo = Sequential()\n",
    "    modelo.add(LSTM(N_UNITS, input_shape=INPUT_SHAPE))\n",
    "    modelo.add(Dense(OUTPUT_LENGTH, activation='linear'))\n",
    "\n",
    "    # Compilación\n",
    "    optimizador = RMSprop(learning_rate=5e-5)\n",
    "    modelo.compile(\n",
    "        optimizer = optimizador,\n",
    "        loss=\"mean_squared_error\",\n",
    "    )\n",
    "    \n",
    "    # Entrenamiento (aproximadamente 1 min usando GPU)\n",
    "    EPOCHS = 80 # Hiperparámetro\n",
    "    BATCH_SIZE = 256 # Hiperparámetro\n",
    "    historia = modelo.fit(\n",
    "        x = x_tr_s,\n",
    "        y = y_tr_s,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        epochs = EPOCHS,\n",
    "        # validation_data = (x_vl_s, y_vl_s),\n",
    "        verbose=2\n",
    "    )\n",
    "    rmse_tr = modelo.evaluate(x=x_tr_s, y=y_tr_s, verbose=0)\n",
    "    # rmse_vl = modelo.evaluate(x=x_vl_s, y=y_vl_s, verbose=0)\n",
    "    rmse_ts = modelo.evaluate(x=x_ts_s, y=y_ts_s, verbose=0)\n",
    "\n",
    "    # Imprimir resultados en pantalla\n",
    "    print('Comparativo desempeños:')\n",
    "    print(f'  RMSE train:\\t {rmse_tr:.3f}')\n",
    "    # print(f'  RMSE val:\\t {rmse_vl:.3f}')\n",
    "    print(f'  RMSE test:\\t {rmse_ts:.3f}')\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011e18a-5454-46aa-9222-aef6b7bfee8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
